{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f10ef13",
   "metadata": {},
   "source": [
    "# 3 Model Training and Prediction\n",
    "\n",
    "This notebook trains and evaluates a predictive model using the imputed feature matrix with depth-2 interaction terms. It includes model selection, training, prediction, evaluation, and export of results.\n",
    "\n",
    "## Contents\n",
    "\n",
    "- **3.1 Load Transformed Dataset**\n",
    "- **3.2 Define Target and Features**\n",
    "- **3.3 Train-Test Split**\n",
    "- **3.4 Model Training**\n",
    "- **3.5 Prediction and Evaluation**\n",
    "- **3.6 Export Predictions**\n",
    "- **3.7 Save Model Artifact**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a177eb",
   "metadata": {},
   "source": [
    "Load essential packages for data access, manipulation, and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5434c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a6916",
   "metadata": {},
   "source": [
    "## 3.1 Load Transformed Dataset\n",
    "\n",
    "Load the imputed feature matrix with depth-2 interactions from the export stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9318108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transformed Dataset\n",
    "imputed_df = pd.read_csv('../data/interaction/earthquake_imputed_2way.csv')\n",
    "features_imputed = ['dmin', 'Year', 'cdi', 'dmin:Year']\n",
    "raw_df = pd.read_csv('../data/interaction/earthquake_raw_2way.csv')\n",
    "features_raw = ['Year', 'nst', 'sig', 'magnitude', 'Year:magnitude', 'depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6c45f",
   "metadata": {},
   "source": [
    "## 3.2 Define Target and Features\n",
    "\n",
    "Specify the target variable for prediction and construct the feature matrix. This step isolates the outcome column (`tsunami`) from the rest of the dataset, preparing inputs for model training.\n",
    "\n",
    "- Target variable: `tsunami` (binary classification)\n",
    "- Feature matrix: all other columns from the transformed dataset\n",
    "- No feature pruning or filtering is applied at this stage\n",
    "- Class distribution is printed for diagnostic clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2d44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target column\n",
    "target = 'tsunami'  # Replace with actual target if different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ddf2a1",
   "metadata": {},
   "source": [
    "## 3.3 Train-Test Split\n",
    "\n",
    "Split the dataset into training and test sets using stratified sampling to preserve class balance. This ensures that the model is trained and evaluated on representative distributions of the target variable.\n",
    "\n",
    "- Split ratio: 80% train / 20% test\n",
    "- Stratification: enabled to preserve class proportions\n",
    "- Random seed: 42 for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e65205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (625, 15)\n",
      "X_test: (157, 15)\n",
      "y_train: (625,)\n",
      "y_test: (157,)\n"
     ]
    }
   ],
   "source": [
    "# Stratified split to preserve class distribution\n",
    "def split_data(df: pd.DataFrame, target_col: str = \"target\", test_size: float = 0.2, random_state: int = 42):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "X_train_imputed, X_test_imputed, y_train_imputed, y_test_imputed = split_data(imputed_df, target)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = split_data(raw_df, target)\n",
    "\n",
    "# Confirm shapes\n",
    "print(\"X_train:\", X_train_imputed.shape)\n",
    "print(\"X_test:\", X_test_imputed.shape)\n",
    "print(\"y_train:\", y_train_imputed.shape)\n",
    "print(\"y_test:\", y_test_imputed.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

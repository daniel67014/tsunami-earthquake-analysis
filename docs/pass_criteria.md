# DA Capstone – Pass Criteria Mapping

| Learning outcome | Expected performance | Completed? |
|------------------|---------------------|------------|
| 1.1 Describe statistics, probability, and data analysis principles. | Notebook: brief explanations of mean, median, standard deviation, hypothesis testing, basic probability; note why foundational. | Yes |
| 1.2 Illustrate application of these core principles. | Dashboard: display mean & variance; Notebook: example t-test or distribution usage (e.g. normal fit). | Yes |
| 2.1 Utilise data analytics tools & Python. | Use Pandas for cleaning/manipulation; Seaborn/Matplotlib for visualization; Plotly interactive in dashboard. | Yes |
| 2.2 Evaluate Python code and queries written. | Show improvements (comments, docstrings, rationale markdown); highlight fixes/optimisation. | Partial |
| 2.3 Implement data analysis techniques, coding, and tool usage. | Perform classification (and optionally regression/clustering) with scikit-learn; show visual (e.g. feature importance). | Yes |
| 3.1 Conduct analysis with methodologies on real dataset. | Follow data cleaning → EDA → feature engineering → modeling → evaluation; reflect steps. | Yes |
| 3.2 Evaluate problem-solving approach & solutions. | Provide commentary on method choices; discuss limitations & alternatives. | Yes |
| 3.3 Design approach, analysis & problem-solving for dataset. | Structured pipeline documented in notebooks and dashboard. | Yes |
| 4.1 Integrate AI tools in analysis tasks. | Note Copilot assistance/examples of suggestions; describe impact. | Yes |
| 4.2 Apply generative AI in storytelling. | Add AI-generated summary or narrative for mixed audiences. | Yes |
| 4.3 Evaluate analysis incl. limitations & alternatives. | Reflect on data limitations, threshold trade-offs, alternative models. | Yes |
| 5.1 Demonstrate effective data collection, cleaning, storage, processing. | Use version control; structured data folders; show missing data handling & storage workflow. | Yes |
| 5.2 Apply best practices in handling/processing data. | Explain collection, cleaning, storage steps; show reproducibility (seeds). | Yes |
| 6.1 Examine ethical issues, privacy, governance. | Add ethics section (bias, fairness, misuse risk) in notebook/dashboard. | Yes |
| 6.2 Discuss legal & social implications. | Mention public data usage, any licensing; note societal impact. | Yes |
| 7.1 Organise project effectively with best practices. | Clear repo structure; README plan; modular notebooks; version control. | Yes |
| 7.2 Select research methodologies applicable to goals. | Explain chosen analytical techniques and rationale. | Yes |
| 8.1 Articulate complex insights to multiple audiences. | Dashboard + README provide both technical metrics and simplified summaries. | Yes |
| 8.2 Employ visualisations & narratives. | Use plots (importances, confusion matrix, PR curve) + explanatory text. | Yes |
| 8.3 Organise documentation for structured sharing. | README, docs, notebook sections clearly segmented. | Yes |
| 9.1 Explore domain applications. | Contextualize tsunami-related earthquake risk and analytics value. | Yes |
| 9.2 Explain how analytics & AI address domain challenges. | Discuss real-time alert potential & model role. | Yes |
| 10.1 Construct project plan (implementation, maintenance, updates, evaluation). | Roadmap outlines future updates, retraining and evaluation cadence. | Yes |
| 10.2 Reflect on practical challenges & considerations. | Provide reflection on feature mismatches, threshold selection, data constraints. | Yes |
| 11.1 Research & experiment with tools/methods. | Multiple models, threshold tuning, interaction mining; documented iterations. | Yes |
| 11.2 Evaluate learning process & preparation for continuous adaptation. | Add reflection section on skills gained & future learning plan. | Yes |

> Status values will be updated as sections are added. This single file is the authoritative checklist.

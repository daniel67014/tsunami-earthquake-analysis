{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f10ef13",
   "metadata": {},
   "source": [
    "# 3 Model Training and Prediction\n",
    "\n",
    "This notebook trains and evaluates a predictive model using the imputed feature matrix with depth-2 interaction terms. It includes model selection, training, prediction, evaluation, and export of results.\n",
    "\n",
    "## Contents\n",
    "\n",
    "- **3.1 Load Transformed Dataset**\n",
    "- **3.2 Define Target and Features**\n",
    "- **3.3 Train-Test Split**\n",
    "- **3.4 Model Training**\n",
    "- **3.5 Prediction and Evaluation**\n",
    "- **3.6 Export Predictions**\n",
    "- **3.7 Save Model Artifact**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a177eb",
   "metadata": {},
   "source": [
    "Load essential packages for data access, manipulation, and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5434c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a6916",
   "metadata": {},
   "source": [
    "## 3.1 Load Transformed Dataset\n",
    "\n",
    "Load the imputed feature matrix with depth-2 interactions from the export stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transformed Dataset\n",
    "imputed_df = pd.read_csv('../data/interaction/earthquake_imputed_2way.csv')\n",
    "features_imputed = ['dmin', 'Year', 'cdi', 'dmin:Year', 'gap', 'sig', 'magnitude', 'depth']\n",
    "raw_df = pd.read_csv('../data/interaction/earthquake_raw_2way.csv')\n",
    "features_raw = ['Year', 'nst', 'sig', 'magnitude', 'Year:magnitude', 'depth']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6c45f",
   "metadata": {},
   "source": [
    "## 3.2 Define Target and Features\n",
    "\n",
    "Specify the target variable for prediction and construct the feature matrix. This step isolates the outcome column (`tsunami`) from the rest of the dataset, preparing inputs for model training.\n",
    "\n",
    "- Target variable: `tsunami` (binary classification)\n",
    "- Feature matrix: all other columns from the transformed dataset\n",
    "- No feature pruning or filtering is applied at this stage\n",
    "- Class distribution is printed for diagnostic clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2d44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target column\n",
    "target = 'tsunami'  # Replace with actual target if different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ddf2a1",
   "metadata": {},
   "source": [
    "## 3.3 Train-Test Split\n",
    "\n",
    "Split the dataset into training and test sets using stratified sampling to preserve class balance. This ensures that the model is trained and evaluated on representative distributions of the target variable.\n",
    "\n",
    "- Split ratio: 80% train / 20% test\n",
    "- Stratification: enabled to preserve class proportions\n",
    "- Random seed: 42 for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e65205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (625, 15)\n",
      "X_test: (157, 15)\n",
      "y_train: (625,)\n",
      "y_test: (157,)\n"
     ]
    }
   ],
   "source": [
    "# Stratified split to preserve class distribution\n",
    "def split_data(df: pd.DataFrame, target_col: str = \"target\", test_size: float = 0.2, random_state: int = 42):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "X_train_imputed, X_test_imputed, y_train_imputed, y_test_imputed = split_data(imputed_df, target)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = split_data(raw_df, target)\n",
    "\n",
    "# Confirm shapes\n",
    "print(\"X_train:\", X_train_imputed.shape)\n",
    "print(\"X_test:\", X_test_imputed.shape)\n",
    "print(\"y_train:\", y_train_imputed.shape)\n",
    "print(\"y_test:\", y_test_imputed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14322560",
   "metadata": {},
   "source": [
    "## 3.4 Model Training\n",
    "\n",
    "Train a tree-based classifier using the training set. Random Forest is selected for its robustness and invariance to feature scaling. Class imbalance is addressed using `class_weight='balanced'`.\n",
    "\n",
    "- Model: `RandomForestClassifier`\n",
    "- Parameters: 100 trees, max depth 8, balanced class weights\n",
    "- Input: imputed feature matrix (`X_train_imputed`, `y_train_imputed`)\n",
    "- Optional: raw matrix training for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c1a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=8, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=8, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=8, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model_imputed = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # handles class imbalance\n",
    ")\n",
    "\n",
    "# Fit model on imputed feature matrix\n",
    "model_imputed.fit(X_train_imputed, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14eb2ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=8, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=8, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=8, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # handles class imbalance\n",
    ")\n",
    "\n",
    "# Fit model on imputed feature matrix\n",
    "model_raw.fit(X_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcdbb54",
   "metadata": {},
   "source": [
    "## 3.5 Prediction and Evaluation\n",
    "\n",
    "Generate predictions on the test set and evaluate model performance using standard classification metrics.\n",
    "\n",
    "- Predictions: binary labels and class probabilities\n",
    "- Metrics: confusion matrix, classification report, ROC AUC\n",
    "- Input: `X_test_imputed`, `y_test_imputed`\n",
    "- Optional: evaluation on raw matrix for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a3bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[87  9]\n",
      " [ 1 60]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95        96\n",
      "           1       0.87      0.98      0.92        61\n",
      "\n",
      "    accuracy                           0.94       157\n",
      "   macro avg       0.93      0.94      0.93       157\n",
      "weighted avg       0.94      0.94      0.94       157\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.9617486338797815\n"
     ]
    }
   ],
   "source": [
    "# Predict labels and probabilities\n",
    "y_pred = model_imputed.predict(X_test_imputed)\n",
    "y_proba = model_imputed.predict_proba(X_test_imputed)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc83ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw ROC AUC: 0.9588456284153005\n"
     ]
    }
   ],
   "source": [
    "# Predict labels and probabilities\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "y_proba_raw = model_raw.predict_proba(X_test_raw)[:, 1]\n",
    "# Evaluation metrics\n",
    "print(\"Raw ROC AUC:\", roc_auc_score(y_test_raw, y_proba_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8851d2",
   "metadata": {},
   "source": [
    "## 3.6 Apply Selected Features\n",
    "\n",
    "Apply the previously selected feature subset to both imputed and raw matrices. This step ensures consistent ancestry and prepares the data for re-training and export.\n",
    "\n",
    "- Source: `selected_features` list defined earlier\n",
    "- Targets: `X_train`, `X_test` for both imputed and raw matrices\n",
    "- Output: refined feature matrices for modeling and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f0f471",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['dmin:gap', 'magnitude:Year', 'magnitude:dmin', 'nst:depth', 'dmin:depth'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Apply selected features\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train_imputed_selected = \u001b[43mX_train_imputed\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures_imputed\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m X_test_imputed_selected = X_test_imputed[features_imputed]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Apply to raw matrix for comparison\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\vsc-projects\\codeinstitute\\projects\\tsunami-earthquake-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3902\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   3901\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m3902\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   3904\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   3905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\vsc-projects\\codeinstitute\\projects\\tsunami-earthquake-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6112\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6114\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6116\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6118\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\vsc-projects\\codeinstitute\\projects\\tsunami-earthquake-analysis\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6175\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6177\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6178\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['dmin:gap', 'magnitude:Year', 'magnitude:dmin', 'nst:depth', 'dmin:depth'] not in index\""
     ]
    }
   ],
   "source": [
    "# Apply selected features\n",
    "X_train_imputed_selected = X_train_imputed[features_imputed]\n",
    "X_test_imputed_selected = X_test_imputed[features_imputed]\n",
    "\n",
    "# Apply to raw matrix for comparison\n",
    "X_train_raw_selected = X_train_raw[features_raw]\n",
    "X_test_raw_selected = X_test_raw[features_raw]\n",
    "\n",
    "# Confirm shape\n",
    "print(\"Selected feature matrix shape:\", X_train_imputed_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1898e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model_imputed_selected = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # handles class imbalance\n",
    ")\n",
    "\n",
    "# Fit model on imputed feature matrix\n",
    "model_imputed_selected.fit(X_train_imputed_selected, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw_selected = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # handles class imbalance\n",
    ")\n",
    "\n",
    "# Fit model on imputed feature matrix\n",
    "model_raw_selected.fit(X_train_raw_selected, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels and probabilities using selected features\n",
    "y_pred = model_imputed_selected.predict(X_test_imputed_selected)\n",
    "y_proba = model_imputed_selected.predict_proba(X_test_imputed_selected)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels and probabilities\n",
    "y_pred_raw = model_raw_selected.predict(X_test_raw_selected)\n",
    "y_proba_raw = model_raw_selected.predict_proba(X_test_raw_selected)[:, 1]\n",
    "# Evaluation metrics\n",
    "print(\"Raw ROC AUC:\", roc_auc_score(y_test_raw, y_proba_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054bd46d",
   "metadata": {},
   "source": [
    "## 3.7 Ensemble Modeling\n",
    "\n",
    "Train AdaBoost and XGBoost classifiers, then combine them with the previously trained Random Forest using a soft-voting ensemble. Evaluate ensemble performance on the imputed-selected test set.\n",
    "\n",
    "- Models: AdaBoost, XGBoost, Random Forest\n",
    "- Ensemble: `VotingClassifier` with soft voting\n",
    "- Evaluation: confusion matrix, classification report, ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1642cc",
   "metadata": {},
   "source": [
    "### 3.7.1 training on `X_train_imputed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e90628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_model.fit(X_train_imputed, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_imputed, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31564ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('ada', ada_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', model_imputed_selected)  # your previously trained Random Forest\n",
    "    ],\n",
    "    voting='soft'  # uses predicted probabilities\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train_imputed, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee024be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada_model.predict(X_test_imputed)\n",
    "y_proba_ada = ada_model.predict_proba(X_test_imputed)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred_ada))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred_ada))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc01f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test_imputed)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test_imputed)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred_xgb))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = ensemble_model.predict(X_test_imputed)\n",
    "y_proba_ensemble = ensemble_model.predict_proba(X_test_imputed)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred_ensemble))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred_ensemble))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61917979",
   "metadata": {},
   "source": [
    "### 3.7.2 training on `X_train_imputed_selected`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41629a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_model.fit(X_train_imputed_selected, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_imputed_selected, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('ada', ada_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', model_imputed_selected)  # your previously trained Random Forest\n",
    "    ],\n",
    "    voting='soft'  # uses predicted probabilities\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train_imputed_selected, y_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada_model.predict(X_test_imputed_selected)\n",
    "y_proba_ada = ada_model.predict_proba(X_test_imputed_selected)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred_ada))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred_ada))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test_imputed_selected)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test_imputed_selected)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred_xgb))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e682ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = ensemble_model.predict(X_test_imputed_selected)\n",
    "y_proba_ensemble = ensemble_model.predict_proba(X_test_imputed_selected)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_imputed, y_pred_ensemble))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_imputed, y_pred_ensemble))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test_imputed, y_proba_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d0332",
   "metadata": {},
   "source": [
    "### 3.7.3 Training summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9120fed",
   "metadata": {},
   "source": [
    "The best model for recall-first tsunami prediction is **RandomForest on the selected 8-feature imputed dataset**:\n",
    "\n",
    "- **Features (8 selected):** `dmin`, `Year`, `cdi`, `dmin:Year`, `gap`, `sig`, `magnitude`, `depth`\n",
    "- **Hyperparameters:** n_estimators=100, max_depth=8, class_weight='balanced', random_state=42\n",
    "- **Primary metric:** Recall on the positive class (tsunami=1) — optimized to minimize false negatives (missed tsunami events)\n",
    "- **Threshold:** Default 0.5 (adjustable via precision–recall sweep for operational requirements)\n",
    "\n",
    "This model balances strong recall with acceptable precision and is simpler/more interpretable than ensemble or boosting alternatives that did not improve recall at the same threshold. The selected features include key distance (dmin), timing (Year), community intensity (cdi), gap imputation, significance, and their interactions — all identified via forward selection in notebook 02_02."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177e61c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5e53f2f",
   "metadata": {},
   "source": [
    "## 3.x Upstream provenance, feature alignment, and evaluation policy\n",
    "\n",
    "This notebook consumes the 2-way feature tables created in 02_02 (Feature Engineering):\n",
    "- data/interaction/earthquake_imputed_2way.csv\n",
    "- data/interaction/earthquake_raw_2way.csv\n",
    "\n",
    "Feature sets used here are aligned to the latest forward-selection results from 02_02 (post-\"gap\" KMeans reassignment):\n",
    "- Imputed features (8): dmin, Year, cdi, dmin:Year, gap, sig, magnitude, depth\n",
    "- Raw features (6): Year, nst, sig, magnitude, Year:magnitude, depth\n",
    "\n",
    "Notes on upstream variability and reproducibility:\n",
    "- In 02_01, gap is imputed by clustering (KMeans with k=3, random_state=42, n_init=10). Cluster labels can permute across runs; after persisting, treat the imputed file as the contract.\n",
    "- If 02_01 or 02_02 are re-run with different seeds/parameters, re-run this notebook to ensure consistency. Expect small drifts in selected features if upstream values shift.\n",
    "\n",
    "Evaluation priorities and decision policy:\n",
    "- Primary metric: recall on the positive class (tsunami=1). Missing a true tsunami is the higher-cost error.\n",
    "- Secondary metrics: precision (to control false alarms) and PR AUC. ROC AUC can be reported but is less informative under class imbalance.\n",
    "- Default classifiers threshold at 0.5; for recall-first operation, we optionally tune this threshold using a precision–recall sweep.\n",
    "\n",
    "Ensemble rationale:\n",
    "- We train RandomForest as a strong baseline with balanced class weights (robust to non-linearities and mixed features).\n",
    "- AdaBoost and XGBoost are explored for complementary decision boundaries. A simple soft-voting ensemble is provided to check for consistent gains.\n",
    "- If ensemble doesn’t improve recall at a given precision, prefer the simplest model that meets policy.\n",
    "\n",
    "Deployment freeze checklist:\n",
    "- Freeze upstream CSVs (02_01 imputed; 02_02 2-way exports) with explicit versions in the repo.\n",
    "- Lock model hyperparameters and the classification threshold selected via the sweep (record the exact value and validation metrics).\n",
    "- Persist the feature list here verbatim and add a schema check (column presence/order) before predicting.\n",
    "- Record sklearn/xgboost versions (requirements.txt) and random seeds used during training.\n",
    "- Export a serialized model artifact alongside a short Model Card (inputs, metrics, threshold, limitations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.x.1 Threshold sweep utility (recall-first tuning)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, recall_score, precision_score\n",
    "\n",
    "# Choose which probability vector to tune against (e.g., y_proba from model_imputed_selected)\n",
    "# Ensure y_test_imputed corresponds to the same set of predictions.\n",
    "proba = y_proba  # adjust if using ensemble or other model\n",
    "true = y_test_imputed.values\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(true, proba)\n",
    "\n",
    "results = []\n",
    "for thr, prec, rec in zip(thresholds, precisions[:-1], recalls[:-1]):\n",
    "    results.append((thr, rec, prec))\n",
    "\n",
    "# Policy: find minimal threshold achieving target recall (e.g., >= 0.88) while keeping precision >= 0.30\n",
    "TARGET_RECALL = 0.88\n",
    "MIN_PRECISION = 0.30\n",
    "\n",
    "candidates = [r for r in results if r[1] >= TARGET_RECALL and r[2] >= MIN_PRECISION]\n",
    "\n",
    "if candidates:\n",
    "    candidates.sort(key=lambda x: x[0])\n",
    "    chosen_thr, chosen_rec, chosen_prec = candidates[0]\n",
    "    tuned_pred = (proba >= chosen_thr).astype(int)\n",
    "    final_rec = recall_score(true, tuned_pred)\n",
    "    final_prec = precision_score(true, tuned_pred)\n",
    "    print(f\"Chosen threshold: {chosen_thr:.3f} | Recall: {final_rec:.3f} | Precision: {final_prec:.3f}\")\n",
    "else:\n",
    "    print(\"No threshold met both recall and precision targets. Consider relaxing MIN_PRECISION or model retraining.\")\n",
    "\n",
    "print(\"Top candidate thresholds (thr, recall, precision):\")\n",
    "for row in candidates[:5]:\n",
    "    print(f\"{row[0]:.3f}\t{row[1]:.3f}\t{row[2]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.x.2 Threshold selection (recall-first) and summary output\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, recall_score, precision_score\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np\n",
    "\n",
    "# Use probabilities from the RF on selected imputed features by default\n",
    "proba = y_proba  # change to y_proba_ensemble or others if desired\n",
    "true = y_test_imputed.values\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(true, proba)\n",
    "\n",
    "# Build (thr, recall, precision) tuples (skip last point where threshold not defined)\n",
    "triples = [(thr, rec, prec) for thr, prec, rec in zip(thresholds, precisions[:-1], recalls[:-1])]\n",
    "\n",
    "TARGET_RECALL = 0.88\n",
    "MIN_PRECISION = 0.30\n",
    "\n",
    "candidates = [t for t in triples if t[1] >= TARGET_RECALL and t[2] >= MIN_PRECISION]\n",
    "\n",
    "if candidates:\n",
    "    # Choose the smallest threshold meeting policy (more positives, higher recall)\n",
    "    candidates.sort(key=lambda x: x[0])\n",
    "    CHOSEN_THRESHOLD, CHOSEN_RECALL, CHOSEN_PRECISION = candidates[0]\n",
    "else:\n",
    "    # Fall back to threshold that maximizes recall, then precision\n",
    "    triples.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    CHOSEN_THRESHOLD, CHOSEN_RECALL, CHOSEN_PRECISION = triples[0]\n",
    "\n",
    "# Compute final metrics at chosen threshold\n",
    "pred = (proba >= CHOSEN_THRESHOLD).astype(int)\n",
    "FINAL_RECALL = recall_score(true, pred)\n",
    "FINAL_PRECISION = precision_score(true, pred)\n",
    "\n",
    "summary_md = f\"\"\"\n",
    "### 3.x.2 Threshold selection summary\n",
    "- Chosen threshold: `{CHOSEN_THRESHOLD:.3f}`\n",
    "- Recall: `{FINAL_RECALL:.3f}`\n",
    "- Precision: `{FINAL_PRECISION:.3f}`\n",
    "- Policy targets: recall ≥ {TARGET_RECALL:.2f}, precision ≥ {MIN_PRECISION:.2f}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary_md))\n",
    "print(\"Top candidate thresholds (thr, rec, prec):\")\n",
    "for row in sorted(candidates, key=lambda x: x[0])[:5]:\n",
    "    print(f\"{row[0]:.3f}\\t{row[1]:.3f}\\t{row[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.x.3 Confusion matrix at chosen threshold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use CHOSEN_THRESHOLD and true/proba from previous cell\n",
    "pred = (proba >= CHOSEN_THRESHOLD).astype(int)\n",
    "cm = confusion_matrix(true, pred)\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (threshold={:.3f})'.format(CHOSEN_THRESHOLD))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf22ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.x.4 Schema check and model persistence\n",
    "\n",
    "import os, json\n",
    "from sklearn import __version__ as sklearn_version\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    xgb_version = xgb.__version__\n",
    "except Exception:\n",
    "    xgb_version = None\n",
    "from joblib import dump\n",
    "\n",
    "# Schema checks for selected features\n",
    "required_features = ['dmin', 'Year', 'cdi', 'dmin:Year', 'gap', 'sig', 'magnitude', 'depth']\n",
    "missing = [f for f in required_features if f not in X_train_imputed_selected.columns]\n",
    "assert not missing, f\"Missing required features: {missing}\"\n",
    "\n",
    "# Persist model artifact and threshold\n",
    "os.makedirs('models', exist_ok=True)\n",
    "MODEL_PATH = 'models/rf_imputed_selected.pkl'\n",
    "THRESHOLD_PATH = 'models/threshold.txt'\n",
    "META_PATH = 'models/model_meta.json'\n",
    "\n",
    "# Save the RF trained on selected imputed features\n",
    "# Assumes variable name model_imputed_selected\n",
    "try:\n",
    "    dump(model_imputed_selected, MODEL_PATH)\n",
    "    with open(THRESHOLD_PATH, 'w') as f:\n",
    "        f.write(str(CHOSEN_THRESHOLD))\n",
    "    meta = {\n",
    "        'features': required_features,\n",
    "        'threshold': CHOSEN_THRESHOLD,\n",
    "        'sklearn_version': sklearn_version,\n",
    "        'xgboost_version': xgb_version,\n",
    "        'random_state': 42,\n",
    "        'model': 'RandomForestClassifier',\n",
    "        'notes': 'Recall-first threshold tuned via precision–recall sweep.'\n",
    "    }\n",
    "    with open(META_PATH, 'w') as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "    print(f\"Saved model -> {MODEL_PATH}\\nSaved threshold -> {THRESHOLD_PATH}\\nSaved meta -> {META_PATH}\")\n",
    "except NameError:\n",
    "    print(\"model_imputed_selected not found. Run training cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
